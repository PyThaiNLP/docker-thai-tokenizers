import deepcut

def tokeniser(sentence, method):
    return deepcut.tokenize(sentence)
